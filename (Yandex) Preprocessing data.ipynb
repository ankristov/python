{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for printing top 5 movies\n",
    "\n",
    "oscar_data = [\n",
    "    ['The Shape of Water', 2017, 6.914, 123, ['sci-fi', 'drama'], 19.4, 195.243464],\n",
    "    ['Moonlight', 2016, 6.151, 110, ['drama'], 1.5, 65.046687],\n",
    "    ['Spotlight', 2015, 7.489, 129, ['drama', 'crime', 'history'], 20.0, 88.346473],\n",
    "    ['Birdman', 2014, 7.604, 119, ['drama', 'comedy'], 18.0, 103.215094],\n",
    "    ['12 Years a Slave', 2013, 7.71, 133, ['drama', 'biography', 'history'], 20.0, 178.371993],\n",
    "    ['Argo', 2012, 7.517, 120, ['thriller', 'drama', 'biography'], 44.5, 232.324128],\n",
    "    ['The Artist', 2011, 7.942, 96, ['drama', 'melodrama', 'comedy'], 15.0, 133.432856],\n",
    "    ['The King\\'s Speech', 2010, 7.977, 118, ['drama', 'biography', 'history'], 15.0, 414.211549],\n",
    "    ['The Hurt Locker', 2008, 7.298, 126, ['thriller', 'drama', 'war', 'history'], 15.0, 49.230772],\n",
    "    ['Slumdog Millionaire', 2008, 7.724, 120, ['drama', 'melodrama'], 15.0, 377.910544],\n",
    "    ['No Country for Old Men', 2007, 7.726, 122, ['thriller', 'drama', 'crime'], 25.0, 171.627166],\n",
    "    ['The Departed', 2006, 8.456, 151, ['thriller', 'drama', 'crime'], 90.0, 289.847354],\n",
    "    ['Crash', 2004, 7.896, 108, ['thriller', 'drama', 'crime'], 6.5, 98.410061],\n",
    "    ['Million Dollar Baby', 2004, 8.075, 132, ['drama', 'sport'], 30.0, 216.763646],\n",
    "    ['The Lord of the Rings: Return of the King', 2003, 8.617, 201, ['fantasy', 'drama', 'adventure'], 94.0, 1119.110941],\n",
    "    ['Chicago', 2002, 7.669, 113, ['musical', 'comedy', 'crime'], 45.0, 306.776732],\n",
    "    ['A Beautiful Mind', 2001, 8.557, 135, ['drama', 'biography', 'melodrama'], 58.0, 313.542341],\n",
    "    ['Gladiator', 2000, 8.585, 155, ['action', 'drama', 'adventure'], 103.0, 457.640427],\n",
    "    ['American Beauty', 1999, 7.965, 122, ['drama'], 15.0, 356.296601],\n",
    "    ['Shakespeare in Love', 1998, 7.452, 123, ['drama', 'melodrama', 'comedy', 'history'], 25.0, 289.317794],\n",
    "    ['Titanic', 1997, 8.369, 194, ['drama', 'melodrama'], 200.0, 2185.372302],\n",
    "    ['The English Patient', 1996, 7.849, 155, ['drama', 'melodrama', 'war'], 27.0, 231.976425],\n",
    "    ['Braveheart', 1995, 8.283, 178, ['drama', 'war', 'biography', 'history'], 72.0, 210.409945],\n",
    "    ['Forrest Gump', 1994, 8.915, 142, ['drama', 'melodrama'], 55.0, 677.386686],\n",
    "    ['Schindler\\'s List', 1993, 8.819, 195, ['drama', 'biography', 'history'], 22.0, 321.265768],\n",
    "    ['Unforgiven', 1992, 7.858, 131, ['drama', 'western'], 14.4, 159.157447],\n",
    "    ['Silence of the Lambs', 1990, 8.335, 114, ['thriller', 'crime', 'mystery', 'drama', 'horror'], 19.0, 272.742922],\n",
    "    ['Dances with Wolves', 1990, 8.112, 181, ['drama', 'adventure', 'western'], 22.0, 424.208848],\n",
    "    ['Driving Miss Daisy', 1989, 7.645, 99, ['drama'], 7.5, 145.793296],\n",
    "    ['Rain Man', 1988, 8.25, 133, ['drama'], 25.0, 354.825435],\n",
    "]\n",
    "\n",
    "def print_top5_sort_by_column(data, column, reverse):\n",
    "    data.sort(key = lambda row: row[column], reverse = reverse)\n",
    "    print('{: <41} | {: >4} | {: >6} | {: >6} | {: >6} | {: >11}'.format('Title', 'Year', 'Rating', 'Length', 'Budget', 'Box office gross'))\n",
    "    for row in data[:5]:\n",
    "        print('{: <41} | {: >4} | {: >6.2f} | {: >6} | {: >6.1f} | {: >11.2f}'.format(row[0], row[1], row[2], row[3], row[5], row[6]))\n",
    "\n",
    "#print_top5(oscar_data)\n",
    "print(\"***Top films based on rating***\")\n",
    "print_top5_sort_by_column(data = oscar_data, column = 2, reverse = True) # sort on rating\n",
    "print()\n",
    "print(\"***Top films based on budget***\") \n",
    "print_top5_sort_by_column(data = oscar_data, column = 5, reverse = True)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def column_sum(data, column):\n",
    "    result = 0\n",
    "    for row in data:\n",
    "        result += row[column]\n",
    "    return result\n",
    "\n",
    "def column_mean(data, column):\n",
    "    mean = column_sum(data, column) / len(data)\n",
    "    return mean\n",
    "\n",
    "mean_score = column_mean(oscar_data, 2)\n",
    "print('Average rating: {:.2f}'.format(mean_score))\n",
    "\n",
    "mean_length = column_mean(oscar_data, 3)\n",
    "print('Average length: {:.2f} min.'.format(mean_length))\n",
    "\n",
    "mean_budget = column_mean(oscar_data, 5)\n",
    "print('Average budget: ${:.2f} mil.'.format(mean_budget))\n",
    "\n",
    "mean_gross = column_mean(oscar_data, 6)\n",
    "print('Average revenue: ${:.2f} mil.'.format(mean_gross))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One of crucial commercial features of a film is its Return on Investment, or ROI. A film's ROI shows the revenues that have been generated by every dollar invested in that film. ROI is calculated by using the following equation:\n",
    "# ROI = (BOX OFFICE GROSS − BUDGET) / BUDGET\n",
    "# Let's write a function that will calculate the ROI of every Oscar-winning film:\n",
    "def add_roi(data):\n",
    "    for i in range(len(data)):\n",
    "        budget = data[i][5]\n",
    "        gross = data[i][6]\n",
    "        roi = (gross - budget) / budget\n",
    "        data[i].append(roi)\n",
    "#add_roi(oscar_data)\n",
    "#print(len(oscar_data[1]))\n",
    "#print(oscar_data)\n",
    "oscar_data.sort(key = lambda row:row[7], reverse = True)\n",
    "print('Movie                                      |    ROI')\n",
    "for row in oscar_data:\n",
    "    print('{: <42} | {: >6.2f}'.format(row[0], row[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As you can see, the most profitable films weren't the ones with the largest box office gross or rating..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter the table, keeping films from the years 2000 and later, then sort it in descending order by box office gross and print the top 5 results\n",
    "def filter_after(data, year_threshold):\n",
    "    result = []\n",
    "    for row in data:\n",
    "        year = row[1]\n",
    "        if year >= year_threshold:\n",
    "            result.append(row)\n",
    "    return result\n",
    "\n",
    "recent_films = filter_after(oscar_data, 2000)\n",
    "print_top5_sort_by_column(data = recent_films,\n",
    "                    column = 6,\n",
    "                    reverse = True)\n",
    "# check\n",
    "min = 3000\n",
    "for row in recent_films:\n",
    "    year = row[1]\n",
    "    if year < min:\n",
    "        min = year\n",
    "print('Min year: ', min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # function for filtering the table by genres\n",
    "def filter_by_genre(data, genre):\n",
    "    result = []\n",
    "    for row in data:\n",
    "        genres = row[4]\n",
    "        if genre in genres:\n",
    "            result.append(row)\n",
    "    return result\n",
    "\n",
    "films_melodrama = filter_by_genre(oscar_data, 'melodrama')\n",
    "print_top5_sort_by_column(data = films_melodrama, column = 0, reverse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Popular genres\n",
    "# function for filtering the table by genres\n",
    "def filter_by_genre(data, genre):\n",
    "    result = []\n",
    "    for row in data:\n",
    "        genres = row[4]\n",
    "        if genre in genres:\n",
    "            result.append(row)\n",
    "    return result\n",
    "\n",
    "all_genres = [\n",
    "    'sci-fi', 'drama', 'crime', 'history', 'comedy', 'biography',\n",
    "    'thriller', 'war', 'melodrama', 'action', 'adventure', 'western',\n",
    "    'mystery', 'horror'\n",
    "]\n",
    "\n",
    "# Create a table (list of lists) with the columns \n",
    "# \"genre name\" and \"number of films\".\n",
    "# Name the variable genres_counts\n",
    "genres_counts = []\n",
    "for genre in all_genres:\n",
    "    # filter the table by genre\n",
    "    # to do this, use the function filter_by_genre()\n",
    "    filtered_data = filter_by_genre(oscar_data, genre)\n",
    "\n",
    "    # calculate the length of the filtered table\n",
    "    # to do this, use the function len()\n",
    "    count = len(filtered_data)\n",
    "\n",
    "    # add the genre name and results of the calculation to the table\n",
    "    # to do this, use the function append()\n",
    "    genres_counts.append([genre, count])\n",
    "\n",
    "# sort the table in descending order\n",
    "# to do this, use the function sort()\n",
    "genres_counts.sort(key = lambda row:row[1], reverse = True)\n",
    "\n",
    "print('Genre        | Number')\n",
    "print('------------------------')\n",
    "for row in genres_counts:\n",
    "    genre = row[0]\n",
    "    count = row[1]\n",
    "    print('{: <11} | {: >10}'.format(genre, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's define some mean parameters for genres\n",
    "def filter_by_genre(data, genre):\n",
    "    result = []\n",
    "    for row in data:\n",
    "        genres = row[4]\n",
    "        if genre in genres:\n",
    "            result.append(row)\n",
    "    return result\n",
    "\n",
    "def column_sum(data, column):\n",
    "    result = 0\n",
    "    for row in data:\n",
    "        result += row[column]\n",
    "    return result\n",
    "\n",
    "def column_mean(data, column):\n",
    "    total = column_sum(data, column)\n",
    "    mean = total / len(data)\n",
    "    return mean\n",
    "\n",
    "def add_roi(data):\n",
    "    for i in range(len(data)):\n",
    "        budget = data[i][5]\n",
    "        gross = data[i][6]\n",
    "        roi = (gross - budget) / budget\n",
    "        data[i].append(roi)\n",
    "\n",
    "def add_cost_per_minute(data):\n",
    "    for i in range(len(data)):\n",
    "        length = data[i][3]\n",
    "        budget = data[i][5]\n",
    "        price_per_minute = budget / length\n",
    "        data[i].append(price_per_minute)\n",
    "\n",
    "# the variable with the selected genres\n",
    "selected_genres = ['history', 'melodrama', 'crime', 'biography', 'thriller']\n",
    "\n",
    "add_roi(oscar_data) \n",
    "add_cost_per_minute(oscar_data)\n",
    "\n",
    "genres_means = []\n",
    "for genre in selected_genres:\n",
    "    # filter the table by genre\n",
    "    films_by_genre = filter_by_genre(oscar_data, genre)\n",
    "    \n",
    "    # calculate the filtered table's means\n",
    "    n = len(films_by_genre)\n",
    "\n",
    "    # mean score (index column 2)\n",
    "    mean_score = column_mean(films_by_genre, column = 2)\n",
    "        \n",
    "    # mean length (index column 3)\n",
    "    mean_length = column_mean(films_by_genre, column = 3)\n",
    "\n",
    "    # mean ROI value (index column 7)\n",
    "    mean_roi = column_mean(films_by_genre, column = 7)\n",
    "\n",
    "    #average cost per minute (index column 8)\n",
    "    mean_cpm = column_mean(films_by_genre, column = 8)\n",
    "\n",
    "    genres_means.append([genre, mean_score, mean_length, mean_roi, mean_cpm])\n",
    "   \n",
    "print('Genre      | Rating | Length  | ROI   | Cost per minute')\n",
    "print('-------------------------------------------------------')\n",
    "for row in genres_means:\n",
    "    print('{: <9} | {: >7.2f} | {: >5.2f} | {: >5.2f} | {: >16.2f}'.format(\n",
    "        row[0], row[1], row[2], row[3], row[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Change column names in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "measurements = [['Sun', 146, 152], # Measurements are stored in a list of lists \n",
    "                                ['Moon', 0.36, 0.41], # measurements\n",
    "                                ['Mercury', 82, 217], \n",
    "                                ['Venus', 38, 261],\n",
    "                                ['Mars', 56, 401],\n",
    "                                ['Jupiter', 588, 968],\n",
    "                                ['Saturn', 1195, 1660],\n",
    "                                ['Uranus', 2750, 3150],\n",
    "                                ['Neptune', 4300, 4700],\n",
    "                                ['Halley\\'s comet', 6, 5400]]\n",
    "# Column names are stored in the header variable.\n",
    "header = ['Celestial bodies ','MIN', 'MAX'] \n",
    "# We'll save the data structure in the celestial variable.\n",
    "celestial = pd.DataFrame(data=measurements, columns=header)\n",
    "\n",
    "print(celestial.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "celestial.set_axis(['celestial_bodies','min_distance','max_distance'],\n",
    "                                     axis='columns', inplace=True)\n",
    "print(celestial.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(celestial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cholera = pd.read_csv('cholera.csv')\n",
    "print(cholera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(cholera.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cholera['imported_cases'] = cholera['imported_cases'].fillna(0)\n",
    "print(cholera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cholera.dropna(subset=['total_cases', 'deaths', 'case_fatality_rate' ], inplace=True)\n",
    "\n",
    "print(cholera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now delete the column on the right with the missing values. Call the dropna() method again. Just like set_axis(), it also has an axis argument. If we assign the 'columns' value to that argument, it will delete every column that has at least one omission\n",
    "cholera.dropna(axis = 'columns', inplace = True)\n",
    "print(cholera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# example\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('music_log_upd_col.csv')\n",
    "\n",
    "df['track_name'] = df['track_name'].fillna('unknown')\n",
    "df['artist_name'] = df['artist_name'].fillna('unknown')\n",
    "df.dropna(subset=['genre_name'], inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Processing dublicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date                 name  points\n",
      "0   2018.01.01         Rafael Nadal   10645\n",
      "1   2018.01.08         Rafael Nadal   10600\n",
      "2   2018.01.29         Rafael Nadal    9760\n",
      "3   2018.02.19        Roger Federer   10105\n",
      "4   2018.03.05        Roger Federer   10060\n",
      "5   2018.03.19        Roger Federer    9660\n",
      "6   2018.04.02  Rafael Nadal Parera    8770\n",
      "7   2018.06.18        Roger Federer    8920\n",
      "8   2018.01.29         Rafael Nadal    9760\n",
      "9   2018.06.25  Rafael Nadal Parera    8770\n",
      "10  2018.07.16  Rafael Nadal Parera    9310\n",
      "11  2018.08.13  Rafael Nadal Parera   10220\n",
      "12  2018.08.20  Rafael Nadal Parera   10040\n",
      "13  2018.09.10  Rafael Nadal Parera    8760\n",
      "14  2018.10.08  Rafael Nadal Parera    8260\n",
      "15  2018.10.15  Rafael Nadal Parera    7660\n",
      "16  2018.11.05       Novak Djokovic    8045\n",
      "17  2018.06.18        Roger Federer    8920\n",
      "18  2018.11.19       Novak Djokovic    9045\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "rating = ['date', 'name', 'points']\n",
    "players = [\n",
    "                ['2018.01.01',  'Rafael Nadal', 10645],\n",
    "                ['2018.01.08',  'Rafael Nadal', 10600],\n",
    "                ['2018.01.29',  'Rafael Nadal', 9760],\n",
    "                ['2018.02.19',  'Roger Federer',    10105], \n",
    "                ['2018.03.05',  'Roger Federer',    10060],\n",
    "                ['2018.03.19',  'Roger Federer',    9660],\n",
    "                ['2018.04.02',  'Rafael Nadal Parera',  8770],\n",
    "                ['2018.06.18',  'Roger Federer',    8920],\n",
    "                ['2018.01.29',  'Rafael Nadal', 9760],\n",
    "                ['2018.06.25',  'Rafael Nadal Parera',  8770],\n",
    "                ['2018.07.16',  'Rafael Nadal Parera',  9310],\n",
    "                ['2018.08.13',  'Rafael Nadal Parera',  10220],\n",
    "                ['2018.08.20',  'Rafael Nadal Parera',  10040],\n",
    "                ['2018.09.10',  'Rafael Nadal Parera',  8760],\n",
    "                ['2018.10.08',  'Rafael Nadal Parera',  8260],\n",
    "                ['2018.10.15',  'Rafael Nadal Parera',  7660],\n",
    "                ['2018.11.05',  'Novak Djokovic',   8045],\n",
    "                ['2018.06.18',  'Roger Federer',    8920],\n",
    "                ['2018.11.19',  'Novak Djokovic',   9045]\n",
    "]\n",
    "tennis = pd.DataFrame(data=players, columns=rating)\n",
    "print(tennis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(19, 3)\n"
     ]
    }
   ],
   "source": [
    "#print(tennis.duplicated())\n",
    "print(tennis.duplicated().sum())\n",
    "print(tennis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 3)\n"
     ]
    }
   ],
   "source": [
    "tennis = tennis.drop_duplicates().reset_index(drop=True)\n",
    "print(tennis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rafael Nadal' 'Roger Federer' 'Rafael Nadal Parera' 'Novak Djokovic']\n"
     ]
    }
   ],
   "source": [
    "print(tennis['name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date                 name  points\n",
      "0   2018.01.01  Rafael Nadal Parera   10645\n",
      "1   2018.01.08  Rafael Nadal Parera   10600\n",
      "2   2018.01.29  Rafael Nadal Parera    9760\n",
      "3   2018.02.19        Roger Federer   10105\n",
      "4   2018.03.05        Roger Federer   10060\n",
      "5   2018.03.19        Roger Federer    9660\n",
      "6   2018.04.02  Rafael Nadal Parera    8770\n",
      "7   2018.06.18        Roger Federer    8920\n",
      "8   2018.06.25  Rafael Nadal Parera    8770\n",
      "9   2018.07.16  Rafael Nadal Parera    9310\n",
      "10  2018.08.13  Rafael Nadal Parera   10220\n",
      "11  2018.08.20  Rafael Nadal Parera   10040\n",
      "12  2018.09.10  Rafael Nadal Parera    8760\n",
      "13  2018.10.08  Rafael Nadal Parera    8260\n",
      "14  2018.10.15  Rafael Nadal Parera    7660\n",
      "15  2018.11.05       Novak Djokovic    8045\n",
      "16  2018.11.19       Novak Djokovic    9045\n"
     ]
    }
   ],
   "source": [
    "tennis['name'] = tennis['name'].replace('Rafael Nadal', 'Rafael Nadal Parera')\n",
    "\n",
    "print(tennis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('music_log_upd_nan.csv')\n",
    "\n",
    "shape_table = df.shape\n",
    "\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "shape_table_update = df.shape\n",
    "\n",
    "if shape_table_update[0] < shape_table[0]:\n",
    "    print('Table smaller, current dimensions:', shape_table_update)\n",
    "    #print('Table smaller, current dimensions: {}, previous: {}'.format(shape_table_update, shape_table))\n",
    "else:\n",
    "    print('Table dimensions unchanged, current dimensions:', shape_table_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('music_log_upd_nan.csv')\n",
    "\n",
    "df['genre_name'] = df['genre_name'].replace('электроника', 'electronic')\n",
    "\n",
    "genre_final_count = df[df['genre_name'] == 'электроника']['genre_name'].count()\n",
    "print(genre_final_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/datasets/music_log_upd_en.csv')\n",
    "print(df.head(10)) # at least first rows look perfect\n",
    "print(df.columns)  # columns names correct\n",
    "na_number = df.isna().sum() # the isna() method detects missing and undefined values\n",
    "print(na_number) # no missing values\n",
    "duplicated_number = df.duplicated().sum()\n",
    "print(duplicated_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/datasets/music_log_upd_en.csv')\n",
    "\n",
    "# If we want to search for people who stand apart from the rest in the Yandex.Music data, we can use the same groupby() method we’re using now to search for a new Earth. We also won't be able to complete the task assigned to us by the mission control either without applying this method.\n",
    "# Before calculating the happiness metric, we will have to study the users whose happiness we’ll be gauging. Who are these people who listen to so much music? Do they have any particular preferences, or do they listen to anything and everything?\n",
    "\n",
    "genre_grouping = df.groupby('user_id')\n",
    "genre_counting = genre_grouping['genre_name'].count()\n",
    "print(genre_counting.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let’s try to track down a user ID for one of the users from our list of music lovers. To do this, we must group the data on the user in order to compile the song genres they listen to.\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/datasets/music_log_upd_en.csv')\n",
    "\n",
    "genre_grouping = df.groupby('user_id')['genre_name']\n",
    "# People who listen to more than 50 songs a day might have a wider preference range. \n",
    "# In order to confirm this, write a get_heavy_user function, which accepts a certain grouping as its groups argument. The function should sift through the entire grouping.\n",
    "def get_heavy_user(groups):\n",
    "    for group_name, group_data in groups:\n",
    "        if len(group_data) > 50:\n",
    "            user = group_name\n",
    "            return user\n",
    "\n",
    "user_id = get_heavy_user(genre_grouping)\n",
    "print(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# You have discovered a music lover in the Yandex.Music table with unique data. This user has listened to more than 50 songs in a single day.\n",
    "# Acquire a table with the songs they listened to.\n",
    "music_user = df[(df['user_id'] == user_id) & df['total_play_seconds'] > 0]\n",
    "print(music_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now we’ll find out how much time this user has spent listening to music of each genre.\n",
    "sum_music_user = music_user.groupby('genre_name')['total_play_seconds'].sum()\n",
    "print(sum_music_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# However, song lengths can vary greatly from genre to genre. It’s important for us to figure out how many songs from each genre the user has played\n",
    "count_music_user = music_user.groupby('genre_name')['genre_name'].count()\n",
    "print(count_music_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We need to position the largest values at the top so the user’s preferences are readily apparent\n",
    "final_sum = count_music_user.sort_values(ascending = False)\n",
    "print(final_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now we will have to do the same with the number of songs the music lover has listened to.\n",
    "final_count = count_music_user.sort_values(ascending = False)\n",
    "print(final_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(df['total_play_seconds'].max())\n",
    "# The longest song was played for over an hour. It would be interesting to know what song was played for that long.\n",
    "df[df['total_play_seconds'] == df['total_play_seconds'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We look for the minimum value, i.e., the shortest song, using the min() method. It stands to reason that there are no measures less than zero in the Yandex.Music data: if a user skipped a song, the ‘total_play_seconds’ value equals 0. (There aren't any negative numbers in this dataset, but sometimes they pop up as the result of errors. For that reason, it's good practice to specify \"> 0\".) Our goal is to determine which songs were listened to for a short period but weren’t skipped immediately.\n",
    "df_min = df[df['total_play_seconds'] > 0]\n",
    "print(df_min['total_play_seconds'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# the name of the song that was skipped after the shortest play.\n",
    "df_min[df_min['total_play_seconds'] == df_min['total_play_seconds'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The mean and median estimate the values in the middle of the data set. If there are just as many people who listen to lots of music as there are people who listen to only a little music, the average would be enough for us. But when there are listeners disassociated from the main group who listen to music for eight hours, their listening data will raise the average significantly. That’s why the median is better for estimating the preferences of a wide range of consumers.\n",
    "# In geometry, the median divides a shape into two parts with equal areas. In statistics, a median divides a data set in half: values less than the median are in one half, while values greater than the median are in the other. It's common sense to sort a list prior to determining the median, in either ascending or descending order.\n",
    "df_stat = df.head(4)\n",
    "print(df_stat['total_play_seconds'].sort_values())\n",
    "print(df_stat['total_play_seconds'].median())\n",
    "df_drop_null = df[df['total_play_seconds'] > 0]\n",
    "# 10.126793\n",
    "print(df_drop_null['total_play_seconds'].median())\n",
    "# 22.579500000000003\n",
    "# In order to make sure that the leading listeners are actually raising the bar, let’s find the average of all the values by using the mean() method\n",
    "print(df_drop_null['total_play_seconds'].mean())\n",
    "# 97.58903824082049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get a table with songs from the most popular genre, Pop (it’s important to capitalize it), excluding skipped songs. Save the results to the pop_music variable\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/datasets/music_log_upd_en.csv')\n",
    "#print(df.head(30))\n",
    "\n",
    "pop_music = df[(df['genre_name'] == 'Pop') & (df['total_play_seconds'] > 0)]\n",
    "#pop_music = df[(df['genre_name'] == 'Pop')] \n",
    "\n",
    "#pop_music = pop_music[pop_music['total_play_seconds'] > 0]\n",
    "print(pop_music.sort_values(by = 'total_play_seconds', ascending = True))\n",
    "# print(pop_music['total_play_seconds'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Find the maximum listening time for a pop song\n",
    "pop_music_max_total_play = pop_music['total_play_seconds'].max()\n",
    "print(pop_music_max_total_play)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get the row from the pop_music table with info on the longest listening time for a ‘pop’ song\n",
    "pop_music_max_info = pop_music[pop_music['total_play_seconds'] == pop_music_max_total_play]\n",
    "print(pop_music_max_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dig for the minimum non-null listening time for a pop song. \n",
    "pop_music_min_total_play = pop_music['total_play_seconds'].min()\n",
    "print(pop_music_min_total_play)\n",
    "\n",
    "# Print data about the pop song that was turned off faster than any other song played\n",
    "pop_music_min_info = pop_music[pop_music['total_play_seconds'] == pop_music_min_total_play]\n",
    "print(pop_music_min_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now calculate the median listening time for pop songs\n",
    "pop_music_median = pop_music['total_play_seconds'].median()\n",
    "print(pop_music_median)\n",
    "# Calculate the average listening time for pop songs\n",
    "pop_music_mean = pop_music['total_play_seconds'].mean()\n",
    "print(pop_music_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Solving Problems and Presenting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Every product’s team decides for itself how to calculate a happiness level, as for Yandex.Music, it’s user median listening time.\n",
    "# We calculate how long every user listened to music. In order to do this, group the DataFrame by user.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
